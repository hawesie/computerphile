{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our states is identified by a label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_labels = [\n",
    "    \"home\",\n",
    "    \"waiting_room\",\n",
    "    \"train\",\n",
    "    \"light_traffic\",\n",
    "    \"medium_traffic\",\n",
    "    \"heavy_traffic\",\n",
    "    \"work\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we run value iteration (VI) we will not use the labels, we will use indexes in matrixes. Therefore we now map each label to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home': 0,\n",
       " 'waiting_room': 1,\n",
       " 'train': 2,\n",
       " 'light_traffic': 3,\n",
       " 'medium_traffic': 4,\n",
       " 'heavy_traffic': 5,\n",
       " 'work': 6}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = {a: i for i, a in enumerate(state_labels)}\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do the same for actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'railway': 0,\n",
       " 'go_home': 1,\n",
       " 'wait': 2,\n",
       " 'relax': 3,\n",
       " 'car': 4,\n",
       " 'drive': 5,\n",
       " 'bike': 6}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_names = [\n",
    "    \"railway\",\n",
    "    \"go_home\",\n",
    "    \"wait\",\n",
    "    \"relax\",\n",
    "    \"car\",\n",
    "    \"drive\",\n",
    "    \"bike\",\n",
    "]\n",
    "actions = {a: i for i, a in enumerate(action_names)}\n",
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up our costs matrix to map from an action (axis 0) to the cost of executing it in a particular state (axis 1). We fill it with `inf` so that all actions have infinite cost. We then specify costs only for the states where the actions are enabled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.full((len(actions), len(states)), fill_value=np.inf, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set all actions in the goal state to cost zero. This prevents the value of the goal state increasing during VI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = \"work\"\n",
    "costs[:, states[goal]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition functions are set up to provide transitions for all states to all other states. This is done in a matrix where the rows correspond to the starting state ($s$) and the columsn to the resultant state ($s'$). The cell $s, s'$ contains the probability of ending up in $s'$ from $s$ given the action was taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we first do this for the \"bike\" action which transitions from home to work with probability 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "[45. inf inf inf inf inf  0.]\n"
     ]
    }
   ],
   "source": [
    "# start with probability zero everywhere\n",
    "t_bike = np.zeros((len(states), len(states)))\n",
    "# set the probability of reach work to 1\n",
    "t_bike[states[\"home\"], states[\"work\"]] = 1\n",
    "# and set the cost of the action\n",
    "costs[actions[\"bike\"], states[\"home\"]] = 45\n",
    "\n",
    "print(t_bike)\n",
    "print(costs[actions[\"bike\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action to drive, once we've chosen car and experienced a traffic level. Transition probability is the same across different traffic levels, but the costs are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_drive = np.zeros((len(states), len(states)))\n",
    "t_drive[states[\"light_traffic\"], states[\"work\"]] = 1\n",
    "t_drive[states[\"medium_traffic\"], states[\"work\"]] = 1\n",
    "t_drive[states[\"heavy_traffic\"], states[\"work\"]] = 1\n",
    "\n",
    "costs[actions[\"drive\"], states[\"light_traffic\"]] = 20\n",
    "costs[actions[\"drive\"], states[\"medium_traffic\"]] = 30\n",
    "costs[actions[\"drive\"], states[\"heavy_traffic\"]] = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relax all the way to work once we're on a train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_relax = np.zeros((len(states), len(states)))\n",
    "t_relax[states[\"train\"], states[\"work\"]] = 1\n",
    "costs[actions[\"relax\"], states[\"train\"]] = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop waiting for the train and go home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_go_home = np.zeros((len(states), len(states)))\n",
    "t_go_home[states[\"waiting_room\"], states[\"home\"]] = 1\n",
    "costs[actions[\"go_home\"], states[\"waiting_room\"]] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the railway. We find a train with some probability. Otherwise we have to wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_railway = np.zeros((len(states), len(states)))\n",
    "t_railway[states[\"home\"], states[\"train\"]] = 0.9\n",
    "t_railway[states[\"home\"], states[\"waiting_room\"]] = 0.1\n",
    "costs[actions[\"railway\"], states[\"home\"]] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose to wait for the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_wait = np.zeros((len(states), len(states)))\n",
    "t_wait[states[\"waiting_room\"], states[\"train\"]] = 0.9\n",
    "t_wait[states[\"waiting_room\"], states[\"waiting_room\"]] = 0.1\n",
    "costs[actions[\"wait\"], states[\"waiting_room\"]] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose to get in to the car. This causes us to experience different traffic levels with different probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_car = np.zeros((len(states), len(states)))\n",
    "t_car[states[\"home\"], states[\"light_traffic\"]] = 0.2\n",
    "t_car[states[\"home\"], states[\"medium_traffic\"]] = 0.7\n",
    "t_car[states[\"home\"], states[\"heavy_traffic\"]] = 0.1\n",
    "costs[actions[\"car\"], states[\"home\"]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we store all the transition functions in a matrix so we can evaluate them all through one matrix operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transitions = np.zeros((len(actions), len(states), len(states)))\n",
    "\n",
    "transitions[actions[\"bike\"]] = t_bike\n",
    "transitions[actions[\"drive\"]] = t_drive\n",
    "transitions[actions[\"relax\"]] = t_relax\n",
    "transitions[actions[\"go_home\"]] = t_go_home\n",
    "transitions[actions[\"railway\"]] = t_railway\n",
    "transitions[actions[\"wait\"]] = t_wait\n",
    "transitions[actions[\"car\"]] = t_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., inf, inf, inf, inf, inf,  0.],\n",
       "       [inf,  2., inf, inf, inf, inf,  0.],\n",
       "       [inf,  3., inf, inf, inf, inf,  0.],\n",
       "       [inf, inf, 35., inf, inf, inf,  0.],\n",
       "       [ 1., inf, inf, inf, inf, inf,  0.],\n",
       "       [inf, inf, inf, 20., 30., 70.,  0.],\n",
       "       [45., inf, inf, inf, inf, inf,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0. , 0.1, 0.9, 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [1. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0.1, 0.9, 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0.2, 0.7, 0.1, 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\n",
       "\n",
       "       [[0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. ]]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a vector of initial state values. These should be greater than zero, and can be arbitrarily large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_init = np.full_like(state_labels, 100, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the goal state, we can set the value of that to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 100., 100., 100., 100.,   0.])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_init[states[goal]] = 0\n",
    "v_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core of VI is the operation below. This muliplies a vector of state values ($v_{n-1}$) by the transition function, then adds the costs. This gives a matrix of Q values, where each row is contains a list of Q values per action, and each column is the Q value for that action reaching that state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = np.dot(transitions, v_init) + costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102.,  inf,  inf,  inf,  inf,  inf,   0.],\n",
       "       [ inf, 102.,  inf,  inf,  inf,  inf,   0.],\n",
       "       [ inf, 103.,  inf,  inf,  inf,  inf,   0.],\n",
       "       [ inf,  inf,  35.,  inf,  inf,  inf,   0.],\n",
       "       [101.,  inf,  inf,  inf,  inf,  inf,   0.],\n",
       "       [ inf,  inf,  inf,  20.,  30.,  70.,   0.],\n",
       "       [ 45.,  inf,  inf,  inf,  inf,  inf,   0.]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the next state value vector by taking a min over the actions in the state (i.e. a min over the columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45., 102.,  35.,  20.,  30.,  70.,   0.])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(q_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same to get the index of the action with the min Q value, i.e. the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 3, 5, 5, 5, 0])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(q_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the previous state value vector to our intial values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_prev = v_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `epsilon` which gives us our stopping condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, run value iteration and extract the policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max. residual: 80.0\n",
      "max. residual: 57.3\n",
      "max. residual: 9.700000000000003\n",
      "max. residual: 0.0\n"
     ]
    }
   ],
   "source": [
    "max_residual = 100\n",
    "while max_residual > epsilon:\n",
    "    q_matrix = np.dot(transitions, v_prev) + costs\n",
    "    v_next = np.min(q_matrix, axis=0)\n",
    "    max_residual = np.max(np.abs(v_next - v_prev))\n",
    "    v_prev = v_next\n",
    "    print(f\"max. residual: {max_residual}\")\n",
    "\n",
    "policy = np.argmin(q_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then inspect the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in state home choose car\n",
      "in state waiting_room choose go_home\n",
      "in state train choose relax\n",
      "in state light_traffic choose drive\n",
      "in state medium_traffic choose drive\n",
      "in state heavy_traffic choose drive\n"
     ]
    }
   ],
   "source": [
    "for state_label, s in states.items():\n",
    "    if state_label != goal:\n",
    "        print(f\"in state {state_label} choose {action_names[policy[s]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also check the value of the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of state home is 33.0\n",
      "the value of state waiting_room is 35.0\n",
      "the value of state train is 35.0\n",
      "the value of state light_traffic is 20.0\n",
      "the value of state medium_traffic is 30.0\n",
      "the value of state heavy_traffic is 70.0\n",
      "the value of state work is 0.0\n"
     ]
    }
   ],
   "source": [
    "for state_label, s in states.items():\n",
    "    print(f\"the value of state {state_label} is {v_next[s]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
